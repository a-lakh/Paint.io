{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import my_nntools as nt\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import itertools\n",
    "\n",
    "import models as models\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_dir=\"./datasets/apple2orange/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loader\n",
    "train_set = ImageDataset(dataset_root_dir, image_size=256, unaligned=True, mode='train')\n",
    "val_set = ImageDataset(dataset_root_dir, image_size=256, unaligned=True, mode='val')\n",
    "test_set = ImageDataset(dataset_root_dir, image_size=256, unaligned=True, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNClassifier(nt.NeuralNetwork):\n",
    "    def __init__(self):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "        self.MSE_Loss = nn.MSELoss()\n",
    "        self.L1_Loss = nn.L1Loss()\n",
    "    \n",
    "    def criterion(self, y, d):\n",
    "        return self.cross_entropy(y, d)    \n",
    "    def criterion_GAN(self, y, d):\n",
    "        return self.MSE_Loss(y, d)\n",
    "    def criterion_cycle(self, y, d):\n",
    "        return self.L1_Loss(y, d)*5\n",
    "    def criterion_identity(self, y, d):\n",
    "        return self.L1_Loss(y, d)*10\n",
    "    \n",
    "class C_GAN(NNClassifier):\n",
    "    def __init__(self, fine_tuning=True):\n",
    "        super(C_GAN, self).__init__()\n",
    "        \n",
    "        self.G_A2B = models.Generator(3, 3)\n",
    "        self.G_B2A = models.Generator(3, 3)\n",
    "        self.D_A = models.Discriminator(3)\n",
    "        self.D_B = models.Discriminator(3)\n",
    "        \n",
    "        self.G_A2B.apply(init_parameters)\n",
    "        self.G_A2B.apply(init_parameters)\n",
    "        self.D_A.apply(init_parameters)\n",
    "        self.D_B.apply(init_parameters)\n",
    "    \n",
    "        self.fake_a_buffer = ReplayBuffer()\n",
    "        self.fake_b_buffer = ReplayBuffer()\n",
    "    \n",
    "    def forward(self, real_a, real_b):        \n",
    "        fake_b = 0.5*(self.G_A2B(real_a) + 1.0)\n",
    "        fake_a = 0.5*(self.G_B2A(real_b) + 1.0)\n",
    "        \n",
    "        return fake_a,fake_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationStatsManager(nt.StatsManager):\n",
    "    def __init__(self):\n",
    "        super(ClassificationStatsManager, self).__init__()\n",
    "        \n",
    "    def init(self):\n",
    "        super(ClassificationStatsManager, self).init()\n",
    "        self.running_loss_G = 0\n",
    "        self.running_loss_D_A = 0\n",
    "        self.running_loss_D_B = 0\n",
    "    \n",
    "    def accumulate(self, loss_G, loss_D_A, loss_D_B):\n",
    "        super(ClassificationStatsManager, self).accumulate(loss_G, loss_D_A, loss_D_B)\n",
    "        self.running_loss_G += loss_G\n",
    "        self.running_loss_D_A += loss_D_A\n",
    "        self.running_loss_D_B += loss_D_B\n",
    "\n",
    "    def summarize(self):\n",
    "        \"\"\"Compute statistics based on accumulated ones\"\"\"\n",
    "        loss_G = self.running_loss_G / self.number_update \n",
    "        loss_D_A = self.running_loss_D_A / self.number_update \n",
    "        loss_D_B = self.running_loss_D_B / self.number_update\n",
    "        return { 'G loss' : loss_G, 'D_A loss' : loss_D_A, 'D_B loss' : loss_D_B}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "net = C_GAN()\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(net.G_A2B.parameters(), \n",
    "                                               net.G_B2A.parameters()), lr=lr)\n",
    "optimizer_D_A = torch.optim.Adam(net.D_A.parameters(), lr=lr)\n",
    "optimizer_D_B = torch.optim.Adam(net.D_B.parameters(), lr=lr)\n",
    "\n",
    "stats_manager = ClassificationStatsManager()\n",
    "exp1 = nt.Experiment(net, train_set, val_set, \n",
    "                     optimizer_G, optimizer_D_A,optimizer_D_B,\n",
    "                     stats_manager, output_dir=\"CGAN\",batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start/Continue training from epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [G loss: 9.5715, D_A loss: 0.2891, D_B loss: 0.3334] (Time: 368.74s)\n",
      "Epoch 2 [G loss: 7.7709, D_A loss: 0.3028, D_B loss: 0.2818] (Time: 367.19s)\n",
      "Epoch 3 [G loss: 7.1713, D_A loss: 0.3072, D_B loss: 0.2670] (Time: 370.86s)\n",
      "Epoch 4 [G loss: 6.9971, D_A loss: 0.3026, D_B loss: 0.2375] (Time: 369.25s)\n",
      "Epoch 5 [G loss: 6.4614, D_A loss: 0.2826, D_B loss: 0.2356] (Time: 364.44s)\n",
      "Epoch 6 [G loss: 6.0706, D_A loss: 0.3054, D_B loss: 0.2256] (Time: 366.72s)\n",
      "Epoch 7 [G loss: 5.9425, D_A loss: 0.3008, D_B loss: 0.1941] (Time: 365.77s)\n",
      "Epoch 8 [G loss: 6.0823, D_A loss: 0.2816, D_B loss: 0.1770] (Time: 372.72s)\n",
      "Epoch 9 [G loss: 5.8023, D_A loss: 0.2792, D_B loss: 0.1753] (Time: 366.25s)\n",
      "Epoch 10 [G loss: 5.4601, D_A loss: 0.2620, D_B loss: 0.2011] (Time: 361.82s)\n",
      "Epoch 11 [G loss: 5.4797, D_A loss: 0.2617, D_B loss: 0.2041] (Time: 368.84s)\n",
      "Epoch 12 [G loss: 5.4490, D_A loss: 0.2338, D_B loss: 0.1852] (Time: 364.47s)\n",
      "Epoch 13 [G loss: 5.3923, D_A loss: 0.2081, D_B loss: 0.1804] (Time: 365.29s)\n",
      "Epoch 14 [G loss: 5.2641, D_A loss: 0.2083, D_B loss: 0.1959] (Time: 365.61s)\n",
      "Epoch 15 [G loss: 5.1168, D_A loss: 0.1955, D_B loss: 0.1939] (Time: 369.36s)\n",
      "Epoch 16 [G loss: 5.2604, D_A loss: 0.1997, D_B loss: 0.1776] (Time: 366.45s)\n",
      "Epoch 17 [G loss: 5.1326, D_A loss: 0.2098, D_B loss: 0.1662] (Time: 368.75s)\n",
      "Epoch 18 [G loss: 4.9751, D_A loss: 0.2047, D_B loss: 0.1694] (Time: 366.50s)\n",
      "Epoch 19 [G loss: 5.3094, D_A loss: 0.1845, D_B loss: 0.1552] (Time: 366.95s)\n",
      "Epoch 20 [G loss: 5.0902, D_A loss: 0.1883, D_B loss: 0.1743] (Time: 366.87s)\n",
      "Epoch 21 [G loss: 4.9732, D_A loss: 0.1979, D_B loss: 0.1807] (Time: 367.54s)\n",
      "Epoch 22 [G loss: 4.8970, D_A loss: 0.1973, D_B loss: 0.1591] (Time: 369.77s)\n",
      "Epoch 23 [G loss: 4.7400, D_A loss: 0.1943, D_B loss: 0.1817] (Time: 368.33s)\n",
      "Epoch 24 [G loss: 4.8710, D_A loss: 0.1851, D_B loss: 0.1562] (Time: 365.35s)\n",
      "Epoch 25 [G loss: 4.9338, D_A loss: 0.1929, D_B loss: 0.1529] (Time: 363.16s)\n",
      "Epoch 26 [G loss: 4.6211, D_A loss: 0.2182, D_B loss: 0.1534] (Time: 367.08s)\n",
      "Epoch 27 [G loss: 5.1335, D_A loss: 0.1941, D_B loss: 0.1196] (Time: 367.65s)\n",
      "Epoch 28 [G loss: 4.8818, D_A loss: 0.1857, D_B loss: 0.1569] (Time: 368.28s)\n",
      "Epoch 29 [G loss: 4.8527, D_A loss: 0.1927, D_B loss: 0.1533] (Time: 365.95s)\n",
      "Epoch 30 [G loss: 5.1059, D_A loss: 0.1337, D_B loss: 0.1443] (Time: 366.34s)\n",
      "Epoch 31 [G loss: 4.9230, D_A loss: 0.2178, D_B loss: 0.1415] (Time: 364.53s)\n",
      "Epoch 32 [G loss: 4.8260, D_A loss: 0.2191, D_B loss: 0.1416] (Time: 363.02s)\n",
      "Epoch 33 [G loss: 4.6933, D_A loss: 0.2014, D_B loss: 0.1513] (Time: 366.93s)\n",
      "Epoch 34 [G loss: 5.4272, D_A loss: 0.0801, D_B loss: 0.1332] (Time: 365.61s)\n",
      "Epoch 35 [G loss: 5.3690, D_A loss: 0.0847, D_B loss: 0.1242] (Time: 365.41s)\n",
      "Epoch 36 [G loss: 4.7947, D_A loss: 0.1832, D_B loss: 0.1324] (Time: 363.33s)\n",
      "Epoch 37 [G loss: 4.9857, D_A loss: 0.2361, D_B loss: 0.0629] (Time: 362.02s)\n",
      "Epoch 38 [G loss: 4.4370, D_A loss: 0.2355, D_B loss: 0.1597] (Time: 368.51s)\n",
      "Epoch 39 [G loss: 4.5429, D_A loss: 0.2105, D_B loss: 0.1645] (Time: 367.84s)\n",
      "Epoch 40 [G loss: 4.7101, D_A loss: 0.2047, D_B loss: 0.1305] (Time: 366.92s)\n",
      "Epoch 41 [G loss: 4.4971, D_A loss: 0.1875, D_B loss: 0.1517] (Time: 363.84s)\n",
      "Epoch 42 [G loss: 4.5137, D_A loss: 0.2013, D_B loss: 0.1557] (Time: 366.46s)\n",
      "Epoch 43 [G loss: 4.3824, D_A loss: 0.2039, D_B loss: 0.1597] (Time: 366.50s)\n",
      "Epoch 44 [G loss: 4.6099, D_A loss: 0.1847, D_B loss: 0.1181] (Time: 364.28s)\n",
      "Epoch 45 [G loss: 4.6531, D_A loss: 0.1832, D_B loss: 0.1490] (Time: 492.42s)\n",
      "Epoch 46 [G loss: 4.4633, D_A loss: 0.1910, D_B loss: 0.1467] (Time: 430.38s)\n",
      "Epoch 47 [G loss: 4.5370, D_A loss: 0.1857, D_B loss: 0.1396] (Time: 475.67s)\n",
      "Epoch 48 [G loss: 4.4539, D_A loss: 0.1890, D_B loss: 0.1296] (Time: 429.64s)\n",
      "Epoch 49 [G loss: 4.5471, D_A loss: 0.1601, D_B loss: 0.1314] (Time: 557.88s)\n",
      "Epoch 50 [G loss: 4.4914, D_A loss: 0.1874, D_B loss: 0.1275] (Time: 1002.36s)\n",
      "Finish training for 50 epochs\n"
     ]
    }
   ],
   "source": [
    "exp1.run(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetResults(net,test_set):\n",
    "    test_loader = td.DataLoader(test_set, batch_size=1, shuffle=False, drop_last=True, pin_memory=True)\n",
    "    net.eval()\n",
    "    \n",
    "    # Create output dirs if they don't exist\n",
    "    if not os.path.exists('output/A'):\n",
    "        os.makedirs('output/A')\n",
    "    if not os.path.exists('output/B'):\n",
    "        os.makedirs('output/B')\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        i=0\n",
    "        for real_a,real_b in test_loader:\n",
    "            real_a, real_b = real_a.to(net.device), real_b.to(net.device)\n",
    "            fake_a,fake_b = net(real_a, real_b)\n",
    "            # Save image files\n",
    "            tv.utils.save_image(fake_a, 'output/A/%04d.png' % (i+1))\n",
    "            tv.utils.save_image(fake_b, 'output/B/%04d.png' % (i+1))\n",
    "            i+=1\n",
    "            \n",
    "            print('Generated images %04d of %04d' % (i, len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated images 0001 of 0006\n",
      "Generated images 0002 of 0006\n",
      "Generated images 0003 of 0006\n",
      "Generated images 0004 of 0006\n",
      "Generated images 0005 of 0006\n",
      "Generated images 0006 of 0006\n"
     ]
    }
   ],
   "source": [
    "GetResults(net,test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
