{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import my_nntools_new as nt\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import itertools\n",
    "\n",
    "import models as models\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NNClassifier(nt.NeuralNetwork):\n",
    "    def __init__(self, lr):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.lr=lr\n",
    "        \n",
    "    def criterion_GAN(y, d):\n",
    "        return nn.MSELoss(y, d)\n",
    "    def criterion_cycle(y, d):\n",
    "        return nn.L1Loss(y, d)*5\n",
    "    def criterion_identity(y, d):\n",
    "        return nn.L1Loss(y, d)*10\n",
    "    \n",
    "class C_GAN(NNClassifier):\n",
    "    def __init__(self, fine_tuning=True):\n",
    "        super(C_GAN, self).__init__()\n",
    "        \n",
    "        self.G_A2B = Generator(3, 3)\n",
    "        self.G_B2A = Generator(3, 3)\n",
    "        self.D_A = Discriminator(3)\n",
    "        self.D_B = Discriminator(3)\n",
    "        \n",
    "        self.G_A2B.apply(init_parameters)\n",
    "        self.G_A2B.apply(init_parameters)\n",
    "        self.D_A.apply(init_parameters)\n",
    "        self.D_B.apply(init_parameters)\n",
    "        \n",
    "        self.optimizer_D_A = torch.optim.Adam(net.D_A.parameters(), lr=self.lr)\n",
    "        self.optimizer_D_B = torch.optim.Adam(net.D_B.parameters(), lr=self.lr)\n",
    "        self.optimizer_G = torch.optim.Adam(itertools.chain(net.G_A2B.parameters(), \n",
    "                                                       net.G_B2A.parameters()), lr=self.lr)\n",
    "        \n",
    "        self.fake_A_buffer = ReplayBuffer()\n",
    "        self.fake_B_buffer = ReplayBuffer()\n",
    "    \n",
    "    def forward(self, real_a, real_b):        \n",
    "        fake_b = 0.5*(self.G_A2B(real_a) + 1.0)\n",
    "        fake_a = 0.5*(selfG_B2A(real_b) + 1.0)\n",
    "        \n",
    "        return fake_a,fake_b\n",
    "        \n",
    "#     def forward(self, real_a, real_b):\n",
    "        \n",
    "#         real_target = Variable(Tensor(opt.batchSize).fill_(1.0), requires_grad=False)\n",
    "#         fake_target = Variable(Tensor(opt.batchSize).fill_(0.0), requires_grad=False)\n",
    "\n",
    "#         ###### Generators A2B and B2A ######\n",
    "#         optimizer_G.zero_grad()\n",
    "\n",
    "#         # Identity loss\n",
    "#         # G_A2B(b) should equal b if real b is fed\n",
    "#         same_b = self.G_A2B(real_b)\n",
    "#         loss_Idt_B = self.criterion_identity(same_b, real_b)\n",
    "#         # G_B2A(a) should equal a if real a is fed\n",
    "#         same_a = netG_B2A(a)\n",
    "#         loss_Idt_A = self.criterion_identity(same_a, real_real_a)\n",
    "\n",
    "#         # GAN loss\n",
    "#         fake_b = self.G_A2B(real_a)\n",
    "#         fake_pred = self.D_B(fake_b)\n",
    "#         loss_GAN_A2B = self.criterion_GAN(fake_pred, real_target)\n",
    "\n",
    "#         fake_a = self.G_B2A(real_B)\n",
    "#         fake_pred = self.D_A(fake_a)\n",
    "#         loss_GAN_B2A = self.criterion_GAN(fake_pred, real_target)\n",
    "\n",
    "#         # Cycle loss\n",
    "#         recovered_a = self.G_B2A(fake_b)\n",
    "#         loss_cycle_ABA = self.criterion_cycle(recovered_a, real_a)\n",
    "\n",
    "#         recovered_b = self.G_A2B(fake_a)\n",
    "#         loss_cycle_BAB = self.criterion_cycle(recovered_b, real_b)\n",
    "\n",
    "#         # Total loss\n",
    "#         loss_G = loss_Idt_A + loss_Idt_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "#         loss_G.backward()\n",
    "        \n",
    "#         optimizer_G.step()\n",
    "#         ###################################\n",
    "\n",
    "#         ###### Discriminator A ######\n",
    "#         optimizer_D_A.zero_grad()\n",
    "\n",
    "#         # Real loss\n",
    "#         real_pred = self.D_A(real_a)\n",
    "#         loss_D_real = self.criterion_GAN(real_pred, real_target)\n",
    "\n",
    "#         # Fake loss\n",
    "#         fake_a = fake_a_buffer.push_and_pop(fake_a)\n",
    "#         fake_pred = self.D_A(fake_a.detach())\n",
    "#         loss_D_fake = self.criterion_GAN(fake_pred, fake_target)\n",
    "\n",
    "#         # Total loss\n",
    "#         loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
    "#         loss_D_A.backward()\n",
    "\n",
    "#         optimizer_D_A.step()\n",
    "#         ###################################\n",
    "\n",
    "#         ###### Discriminator B ######\n",
    "#         optimizer_D_B.zero_grad()\n",
    "\n",
    "#         # Real loss\n",
    "#         real_pred = self.D_B(real_b)\n",
    "#         loss_D_real = self.criterion_GAN(real_pred, real_target)\n",
    "        \n",
    "#         # Fake loss\n",
    "#         fake_b = fake_b_buffer.push_and_pop(fake_b)\n",
    "#         fake_pred = self.D_B(fake_b.detach())\n",
    "#         loss_D_fake = self.criterion_GAN(fake_pred, fake_target)\n",
    "\n",
    "#         # Total loss\n",
    "#         loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "#         loss_D_B.backward()\n",
    "\n",
    "#         optimizer_D_B.step()\n",
    "#         ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClassificationStatsManager(nt.StatsManager):\n",
    "    def __init__(self):\n",
    "        super(ClassificationStatsManager, self).__init__()\n",
    "        \n",
    "    def init(self):\n",
    "        super(ClassificationStatsManager, self).init()\n",
    "        self.running_loss_G = 0\n",
    "        self.running_loss_D_A = 0\n",
    "        self.running_loss_D_B = 0\n",
    "    \n",
    "    def accumulate(self, loss_G, loss_D_A, loss_D_B):\n",
    "        super(ClassificationStatsManager, self).accumulate(loss_G, loss_D_A, loss_D_B)\n",
    "        self.running_loss_G += loss_G\n",
    "        self.running_loss_D_A += loss_D_A\n",
    "        self.running_loss_D_B += loss_D_B\n",
    "\n",
    "    def summarize(self):\n",
    "        \"\"\"Compute statistics based on accumulated ones\"\"\"\n",
    "        loss_G = self.running_loss_G / self.number_update \n",
    "        loss_D_A = self.running_loss_D_A / self.number_update \n",
    "        loss_D_B = self.running_loss_D_B / self.number_update\n",
    "        return { 'G loss' : loss_G, 'D_A loss' : loss_D_A, 'D_B loss' : loss_D_B}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_root_dir=\"/datasets/ee285f-public/caltech_ucsd_birds/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset loader\n",
    "train_set = ImageDataset(dataset_root_dir, image_size=(512, 512), unaligned=True, mode='train')\n",
    "val_set = ImageDataset(dataset_root_dir, image_size=(512, 512), unaligned=True, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "net = C_GAN(lr)\n",
    "net = net.to(device)\n",
    "\n",
    "stats_manager = ClassificationStatsManager()\n",
    "exp1 = nt.Experiment(net, train_set, val_set, stats_manager, output_dir=\"CGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp1.run(num_epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
